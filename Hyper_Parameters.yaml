Sound:
    N_Mel: 100
    Hop_Size: 256
    Sample_Rate: 24000
    F0_Min: 65  # C2
    F0_Max: 2094    # C7

Tokens: 71
Languages: 1
Speakers: 109
Durations: 4096
Use_Between_Padding: true

Encoder:
    Size: 384
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1

Prompter:
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1

Duration_Predictor:
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1

F0_Predictor:
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1

Eliminator:
    Size: 256
    Kernel_Size: 3

Frame_Prior_Network:
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1


CFM:
    Size: 512
    Scheduler: 'Uniform' # 'Cosmap'
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1
    Token_Predictor:
        Size: 256
        LSTM:
            Stack: 2
            Dropout_Rate: 0.0
    Use_CFG: true


Token_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Token.yaml'
Latent_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Latent_Info.yaml'
Mel_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Mel_Info.yaml'
F0_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/F0_Info.yaml'
Speaker_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Speaker_Info.yaml'
Emotion_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Emotion_Info.yaml'
Language_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Language_Info.yaml'
Gender_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Gender_Info.yaml'
Language_and_Gender_Info_by_Speaker_Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Language_and_Gender_Info_by_Speaker.yaml'
Train:
    Pattern_Cache: false
    Train_Pattern:
        Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Train'
        Metadata_File: 'METADATA.PICKLE'
        Feature_Length:
            Min: 50
            Max: 800
        Text_Length:
            Min: 1
            Max: 200
        Accumulated_Dataset_Epoch: 1    # This is to prevent slow down from torch.utils.data.DataLoader when the number of patterns is small.
        Augmentation_Ratio: 0.05
    Eval_Pattern:
        Path: '/mnt/f/Datasets/24K.RectifiedFlowTTS.VCTK.Mel/Eval'
        Metadata_File: 'METADATA.PICKLE'
        Feature_Length:
            Min: 50
            Max: 800
        Text_Length:
            Min: 10
            Max: 200
    Num_Workers: 2
    Batch_Size: 16
    Learning_Rate:
        Initial: 1.0e-4
        Decay: 0.999875
        Decay_Epoch: 1
    ADAM:
        Beta1: 0.9
        Beta2: 0.999
        Epsilon: 1.0e-7
    Weight_Decay: 1.0e-6
    CFG_Alpha: 0.1  # only using when Use_CFG is true
    Accumulated_Gradient_Step: 1 # 25    
    Gradient_Norm: 1.0
    Discriminator_Lambda: 1.0
    Max_Step: 300000
    Discrimination_Step: 0
    Checkpoint_Save_Interval: 5000
    Logging_Interval: 1
    Evaluation_Interval: 1000
    Inference_Interval: 5000
    Initial_Inference: true
    Inference_in_Train:
        Text: [
            'Do not kill the goose that lays the golden eggs.',
            'A good medicine tastes bitter.',
            'Do not count your chickens before they hatch.',
            'If you laugh, blessings will come your way.'
            ]
        Reference: [
            '/mnt/f/Rawdata/VCTK092/wav48/p225/p225_001_mic1.flac',
            '/mnt/f/Rawdata/VCTK092/wav48/p264/p264_002_mic1.flac',
            '/mnt/f/Rawdata/VCTK092/wav48/p271/p271_002_mic2.flac',
            '/mnt/f/Rawdata/LJSpeech/wavs/LJ032-0206.wav'
            ]
        Language: [
            'English',
            'English',
            'English',
            'English'
            ]

Inference_Batch_Size: 8
Inference_Path: './results/VCTK_CFG_Uniform_Mel/Inference'
Checkpoint_Path: './results/VCTK_CFG_Uniform_Mel/Checkpoint'
Log_Path: './results/VCTK_CFG_Uniform_Mel/Log'

Weights_and_Biases:
    Use: false
    Project: 'RectifiedFlowTTS'
    Entity: 'codejin'
    Name: 'Test'
    Save_Checkpoint:
        Use: false
        Interval: 50000 # Unlike local, The capacity of WandB is small.

Use_Mixed_Precision: false
# Use_Multi_GPU: true
# Device: '0,1,2,3,4,5,6,7'
Use_Multi_GPU: false
Device: '0'
